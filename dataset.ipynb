{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5de6cad-f543-4943-b7a7-6e32db90c8b7",
   "metadata": {},
   "source": [
    "# 1. Label Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "389367f6-42b5-4709-8961-74b45ae04d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1m\u001b[97mINFO   \u001b[0m] \u001b[36m__init__\u001b[0m:\u001b[36mget_config\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1m\u001b[97mLoading config file from: /Users/sarvzz/.labelmerc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e6324-929d-4b08-a7a8-2a32ff82bf1c",
   "metadata": {},
   "source": [
    "# 2. Apply Image Augmentation on Images and Labels using Albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854fe9b-30b3-4d70-aa23-656ec2345cd0",
   "metadata": {},
   "source": [
    "### 2.1 Setup Alumentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8145f7e-505b-4ee6-96fd-1b696b42bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa71dfd2-3578-445d-a75c-d212a239b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking our original image size\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# img = cv2.imread(os.path.join('V16-2023-10-12','data','images','frame_42.jpg'))\n",
    "# img_size = img.shape\n",
    "# img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e965b2dc-097f-4e3b-943d-e9a31c722bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([#alb.CenterCrop(width=700, height=700), \n",
    "                         #alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2)], \n",
    "                         bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb8003-fa61-4c21-97eb-1d5a27157f2f",
   "metadata": {},
   "source": [
    "### 2.2 Load a Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be32cf53-f43d-4044-9a95-4ad606bf3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('V16-2023-10-12','data','images','frame_00.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a51b2e0-39a6-42a5-b43b-cfd386319cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join('V16-2023-10-12','data','labels','frame_00.json'),'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51becb90-4c5d-4d6f-8faf-ee17997261cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.492358803986711,\n",
       "  0.3770321151716501,\n",
       "  0.5444075304540421,\n",
       "  0.42741971207087487),\n",
       " (0.24928017718715392,\n",
       "  0.37758582502768545,\n",
       "  0.3002214839424142,\n",
       "  0.426312292358804)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_normalized = (label['shapes'][0]['points'][0][0])/700    #LeftEye   (x1)\n",
    "y1_normalized = (label['shapes'][0]['points'][0][1])/700    #LeftEye   (y1)\n",
    "x2_normalized = (label['shapes'][0]['points'][1][0])/700    #LeftEye   (x2)\n",
    "y2_normalized = (label['shapes'][0]['points'][1][1])/700    #LeftEye   (y2)\n",
    "\n",
    "x3_normalized = (label['shapes'][1]['points'][0][0])/700    #RightEye  (x3)\n",
    "y3_normalized = (label['shapes'][1]['points'][0][1])/700    #RightEye  (y3)\n",
    "x4_normalized = (label['shapes'][1]['points'][1][0])/700    #RightEye  (x4)\n",
    "y4_normalized = (label['shapes'][1]['points'][1][1])/700    #RightEye  (y4)\n",
    "\n",
    "\n",
    "# Create a list of normalized bounding box coordinates\n",
    "# LeftEye_coords = [x1_normalized, y1_normalized, x2_normalized, y2_normalized]\n",
    "# RightEye_coords = [x3_normalized, y3_normalized, x4_normalized, y4_normalized]\n",
    "\n",
    "# Create a list of bboxes with LeftEye and RightEye coordinates\n",
    "bboxes = [(x1_normalized, y1_normalized, x2_normalized, y2_normalized),(x3_normalized, y3_normalized, x4_normalized, y4_normalized)]\n",
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5adcdcb-0123-481c-86b9-67c5f58a48a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         ...,\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149]],\n",
       " \n",
       "        [[120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         ...,\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149]],\n",
       " \n",
       "        [[120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         [120, 153, 175],\n",
       "         ...,\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149],\n",
       "         [103, 132, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[138, 130, 173],\n",
       "         [164, 159, 201],\n",
       "         [178, 175, 217],\n",
       "         ...,\n",
       "         [148, 121, 153],\n",
       "         [144, 119, 151],\n",
       "         [134, 110, 139]],\n",
       " \n",
       "        [[135, 128, 173],\n",
       "         [165, 161, 206],\n",
       "         [174, 172, 217],\n",
       "         ...,\n",
       "         [149, 122, 154],\n",
       "         [146, 121, 153],\n",
       "         [131, 108, 137]],\n",
       " \n",
       "        [[137, 133, 177],\n",
       "         [167, 165, 211],\n",
       "         [171, 170, 217],\n",
       "         ...,\n",
       "         [143, 118, 149],\n",
       "         [148, 123, 155],\n",
       "         [134, 111, 140]]], dtype=uint8),\n",
       " 'bboxes': [(0.492358803986711,\n",
       "   0.3770321151716501,\n",
       "   0.5444075304540421,\n",
       "   0.42741971207087487),\n",
       "  (0.24928017718715392,\n",
       "   0.37758582502768545,\n",
       "   0.3002214839424142,\n",
       "   0.426312292358804)],\n",
       " 'class_labels': ['Iris', 'Iris']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented = augmentor(image=img, bboxes=bboxes, class_labels=['Iris','Iris'])\n",
    "augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a29bf892-3e5c-45e7-850d-a32037f0fb97",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m               \u001b[38;5;66;03m# tuple(np.multiply(augmented['bboxes'][0][:2], [450, 450]).astype(int)),\u001b[39;00m\n\u001b[1;32m     10\u001b[0m               \u001b[38;5;66;03m# tuple(np.multiply(augmented['bboxes'][0][2:], [450, 450]).astype(int)),\u001b[39;00m\n\u001b[1;32m     11\u001b[0m               \u001b[38;5;66;03m# (0, 255, 0), 2)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     14\u001b[0m               \u001b[38;5;28mtuple\u001b[39m((augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m2\u001b[39m])),\n\u001b[1;32m     15\u001b[0m               \u001b[38;5;28mtuple\u001b[39m((augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m:])),\n\u001b[1;32m     16\u001b[0m               (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cv2.rectangle(augmented['image'], \n",
    "              tuple((augmented['bboxes'][0][:2])),\n",
    "              tuple((augmented['bboxes'][0][2:])),\n",
    "              (0, 255, 0), 2)\n",
    "\n",
    "              # tuple(np.multiply(augmented['bboxes'][0][:2], [450, 450]).astype(int)),\n",
    "              # tuple(np.multiply(augmented['bboxes'][0][2:], [450, 450]).astype(int)),\n",
    "              # (0, 255, 0), 2)\n",
    "\n",
    "cv2.rectangle(augmented['image'], \n",
    "              tuple((augmented['bboxes'][1][:2])),\n",
    "              tuple((augmented['bboxes'][1][2:])),\n",
    "              (0, 255, 0), 2)\n",
    "\n",
    "              # tuple(np.multiply(augmented['bboxes'][1][:2], [450, 450]).astype(int)),\n",
    "              # tuple(np.multiply(augmented['bboxes'][1][2:], [450, 450]).astype(int)),\n",
    "              # (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f65ae8-bf38-4b56-87f6-db0a48fc7a33",
   "metadata": {},
   "source": [
    "### 2.3 Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1481ca7d-e96e-4142-b3be-7328532f76dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image must be numpy array type\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from albumentations import Compose, BboxParams\n",
    "\n",
    "#for partition in ['train', 'test', 'validate']:\n",
    "for partition in ['train']:\n",
    "    image_folder = os.path.join('data-1', partition, 'images')\n",
    "    label_folder = os.path.join('data-1', partition, 'labels')\n",
    "\n",
    "    for image in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, image)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "\n",
    "        #bboxes = [[0, 0, 0.00001, 0.00001], [0, 0, 0.00001, 0.00001]] \n",
    "        label_path = os.path.join(label_folder, f'{os.path.splitext(image)[0]}.json')\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            if len(label['shapes']) >= 2:\n",
    "\n",
    "                x1_normalized = (label['shapes'][0]['points'][0][0]) #/450    #LeftEye   (x1)\n",
    "                y1_normalized = (label['shapes'][0]['points'][0][1]) #/450    #LeftEye   (y1)\n",
    "                x2_normalized = (label['shapes'][0]['points'][1][0]) #/450    #LeftEye   (x2)\n",
    "                y2_normalized = (label['shapes'][0]['points'][1][1]) #/450    #LeftEye   (y2)\n",
    "                \n",
    "                x3_normalized = (label['shapes'][1]['points'][0][0]) #/450    #RightEye  (x3)\n",
    "                y3_normalized = (label['shapes'][1]['points'][0][1]) #/450    #RightEye  (y3)\n",
    "                x4_normalized = (label['shapes'][1]['points'][1][0]) #/450    #RightEye  (x4)\n",
    "                y4_normalized = (label['shapes'][1]['points'][1][1]) #/450    #RightEye  (y4)\n",
    "\n",
    "            else: \n",
    "                x1_normalized = 0  \n",
    "                y1_normalized = 0\n",
    "                x2_normalized = 0\n",
    "                y2_normalized = 0\n",
    "                x3_normalized = 0 \n",
    "                y3_normalized = 0\n",
    "                x4_normalized = 0\n",
    "                y4_normalized = 0\n",
    "\n",
    "            \n",
    "            # Create a list of bboxes with LeftEye and RightEye coordinates\n",
    "            bboxes = [(x1_normalized, y1_normalized, x2_normalized, y2_normalized),(x3_normalized, y3_normalized, x4_normalized, y4_normalized)]\n",
    "        \n",
    "\n",
    "        try: \n",
    "            for x in range(2):\n",
    "                augmented = augmentor(image=img, bboxes=bboxes, class_labels=['Iris', 'Iris'])\n",
    "                cv2.imwrite(os.path.join('V16-2023-10-12','data','aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [[0,0,0,0],[0,0,0,0]]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = [augmented['bboxes'][0],augmented['bboxes'][1]]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [[0,0,0,0],[0,0,0,0]]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('V16-2023-10-12','data','aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca325b5-d10f-4eee-9b58-7093a5d78151",
   "metadata": {},
   "source": [
    "# 3. LabelMe to COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f127b7a8-7ec8-44b3-aeae-bf014f18a612",
   "metadata": {},
   "source": [
    "### 3.1 Convert LabelMe to COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d06bc7-38a0-4a76-9b20-3a91c0bb3d25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting labelme2coco\n",
      "  Using cached labelme2coco-0.2.4-py3-none-any.whl (19 kB)\n",
      "Collecting sahi>=0.8.19 (from labelme2coco)\n",
      "  Obtaining dependency information for sahi>=0.8.19 from https://files.pythonhosted.org/packages/bf/2b/026f0861137499edca43263679f9e4ce21314b67c34c8d74c12f2833b8c3/sahi-0.11.14-py3-none-any.whl.metadata\n",
      "  Using cached sahi-0.11.14-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from labelme2coco) (4.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from jsonschema>=2.6.0->labelme2coco) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from jsonschema>=2.6.0->labelme2coco) (0.19.3)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.32 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (4.8.0.74)\n",
      "Collecting shapely>=1.8.0 (from sahi>=0.8.19->labelme2coco)\n",
      "  Downloading shapely-2.0.1-cp311-cp311-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (4.65.0)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (9.4.0)\n",
      "Collecting pybboxes==0.1.6 (from sahi>=0.8.19->labelme2coco)\n",
      "  Using cached pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (6.0)\n",
      "Collecting fire (from sahi>=0.8.19->labelme2coco)\n",
      "  Using cached fire-0.5.0.tar.gz (88 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting terminaltables (from sahi>=0.8.19->labelme2coco)\n",
      "  Using cached terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (2.29.0)\n",
      "Requirement already satisfied: click in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from sahi>=0.8.19->labelme2coco) (8.1.6)\n",
      "Requirement already satisfied: numpy in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from pybboxes==0.1.6->sahi>=0.8.19->labelme2coco) (1.24.2)\n",
      "Requirement already satisfied: six in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from fire->sahi>=0.8.19->labelme2coco) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from fire->sahi>=0.8.19->labelme2coco) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from requests->sahi>=0.8.19->labelme2coco) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from requests->sahi>=0.8.19->labelme2coco) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from requests->sahi>=0.8.19->labelme2coco) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sarvzz/miniconda3/lib/python3.11/site-packages (from requests->sahi>=0.8.19->labelme2coco) (2023.7.22)\n",
      "Using cached sahi-0.11.14-py3-none-any.whl (104 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=bbd96e4a786b9c24b67b89c0ab84da5ae6a5e0e4e29471d15b53375984b289f8\n",
      "  Stored in directory: /Users/sarvzz/Library/Caches/pip/wheels/a7/ee/a5/19e91481be8bea594935d137578bfe77d6bf905e4595336f6b\n",
      "Successfully built fire\n",
      "Installing collected packages: terminaltables, shapely, pybboxes, fire, sahi, labelme2coco\n",
      "Successfully installed fire-0.5.0 labelme2coco-0.2.4 pybboxes-0.1.6 sahi-0.11.14 shapely-2.0.1 terminaltables-3.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U labelme2coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0287566a-082f-4606-9ffc-c0c91d440f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme2coco \n",
    "import os\n",
    "import json\n",
    "#from pycocotools.coco import COCO\n",
    "#from pycocotools import mask as maskUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26d8c8d1-5ac9-467e-9007-2475a058aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 450 listed files in folder labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labelme annotations to COCO format: 100%|█| 450/450 [00:00<00:00, 166\n",
      "10/13/2023 10:20:12 - INFO - labelme2coco -   Converted annotations in COCO format is exported to V16-2023-10-12/data/coco_annotations/dataset.json\n"
     ]
    }
   ],
   "source": [
    "# input folder \n",
    "labelme_folder = 'V16-2023-10-12/data/labels'\n",
    "\n",
    "# output folder\n",
    "#export_dir = 'V10-2023-09-27/data/train/coco_annotations/coco_annotation.json'\n",
    "export_dir = 'V16-2023-10-12/data/coco_annotations'\n",
    "\n",
    "# convert labelme annotations to coco\n",
    "labelme2coco.convert(labelme_folder, export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4670e2c-062c-4d90-bba7-7e60e02a16b2",
   "metadata": {},
   "source": [
    "# 4. Change 'imagePath' in .json file to it's file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1bab0a-5c53-4234-8fd2-0de1c95d2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Labelme directory\n",
    "json_dir = 'upload_data/labels/'\n",
    "\n",
    "# Iterate through all json files\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if json_file.endswith('.json'):\n",
    "        \n",
    "        # Read the json file \n",
    "        with open(os.path.join(json_dir, json_file), 'r') as f:\n",
    "            labelme_data = json.load(f)\n",
    "\n",
    "        \n",
    "        # Extract json file name\n",
    "        json_file_name = os.path.splitext(json_file)[0]\n",
    "        \n",
    "        # Update the 'imagePath' with .jpg\n",
    "        labelme_data['imagePath'] = f'{json_file_name}.jpg'\n",
    "\n",
    "        # Write the updated json data back to the file\n",
    "        with open(os.path.join(json_dir, json_file), 'w') as f:\n",
    "            json.dump(labelme_data, f, indent=4)\n",
    "    \n",
    "    # else:\n",
    "    #     print(f'skipping empty file: {json_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7afbe6-6df6-44b3-bdbe-07c48c6b12ec",
   "metadata": {},
   "source": [
    "# 5. VOC XML to COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eb79c-f58f-4ffc-b0e9-e0e775ba5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define path to PASCAL VOC XML file\n",
    "xml_file = 'annotated images/xml annotations/annotations.xml'\n",
    "\n",
    "# Initialize the COCO-format dictionary\n",
    "coco_data = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': []\n",
    "}\n",
    "\n",
    "# Mapping of class names to COCO category IDs\n",
    "class_to_id = {\n",
    "    'Pupilmargin': 1,\n",
    "    'PupilCenter': 2\n",
    "}\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Iterate through the 'image' elements in the XML\n",
    "for image_elem in root.findall('image'):\n",
    "    image_info = {\n",
    "        'id': int(image_elem.get('id')),\n",
    "        'file_name': image_elem.get('name'),\n",
    "        'width': int(image_elem.get('width')),\n",
    "        'height': int(image_elem.get('height'))\n",
    "        \n",
    "    }\n",
    "\n",
    "coco_data['images'].append(image_info)\n",
    "\n",
    "# Extract object annotations for each image\n",
    "for box_elem in image_elem.findall('box'):\n",
    "    category_name = box_elem.get('label')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7fe38-97dc-4623-a6f6-fa2e00651052",
   "metadata": {},
   "source": [
    "# 6. JSON File Name - Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1e90fda2-9db5-4eca-9f40-8811c5c3f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0f1bcaa-0d6a-410e-8699-3f0a04c6ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create copies and update file extension \n",
    "def duplicate_files_with_extensions(file_path, num_copies):\n",
    "    # Split the file path into base name and extension\n",
    "    base_name, file_extension = file_path.rsplit('.', 1)\n",
    "\n",
    "    # Create copies of the file with different extensions\n",
    "    for i in range(num_copies):\n",
    "        new_file_name = f'{base_name}.{i}.{file_extension}'\n",
    "        shutil.copy(file_path, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c8c29c0-e64b-4f15-ba7a-c92696f499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file updates\n",
    "file_path = 'V16-2023-10-12/data/testing_files/frame_00.json'\n",
    "num_copies = 3\n",
    "\n",
    "duplicate_files_with_extensions(file_path, num_copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8796b8-1108-4208-81ab-57ecf136a743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
